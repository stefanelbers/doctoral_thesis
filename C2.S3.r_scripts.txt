
******** READ FIRST ********

This *.txt file contains:
1) index.Rmd (a flexdashboard file that contains the multimedia appendix and links to 4 other r-scripts.
-- load_packages.R
-- load_data.R
-- shiny_fp_prep_md.R


2) Additional r-scripts that have been used to perform the analysis that have been published in the manuscript:
- questionnaires_dataframe.R
- results_analysis.R
- risk_of_bias_table.R
- shiny_forest_plot_static_analysis.R




******** index.Rmd ********


---
title: "flexdashboard: IMPT meta analysis"
runtime: shiny
output: 
  flexdashboard::flex_dashboard:
    social: menu
    source_code: embed 
    vertical_layout: scroll
---


```{r load packages, include=FALSE}
# Package names

library(dplyr)
library(DiagrammeR)
library(DT)
library(flexdashboard)
library(forestplot)
library(formattable)
library(data.table)
library(gsheet)
library(htmltools)
library(Hmisc)
library(lessR)
library(magrittr)
library(meta)
library(metafor)
library(plotly)
library(png)
library(PRISMAstatement)
library(psych)
library(reactable)
library(readxl)
library(rsconnect)
library(shiny)
library(stringr)
library(summarytools)
library(tidyr)
library(tidyverse)
library(wesanderson)
```

```{r load data, include=FALSE}
source("load_data.R", local = knitr::knit_global())
```

```{r prepare descriptive tables, include=FALSE}
source("descriptive_tables_md.R", local = knitr::knit_global())
```

```{r questionnaires dataframe, echo=FALSE}
source("questionnaires_dataframe.R", local = knitr::knit_global())
```

```{r}
source("shiny_fp_prep_md.R", local = knitr::knit_global())
```

Home {data-orientation=columns}
=======================================================================

Column {.sidebar data-width=500}
-------------------------------------
### Interdisciplinary multimodal pain treament programs: a living repository

This online repository contains all study data of a systematic review and meta analysis on the development over time of interdisciplinary multimodal pain treatment (IMPT) programs. [click here](https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=76093) for the study protocol. <br />

The study procedures are depicted in the figure on the right side. The main advantage of this infrastructure is that data extraction forms that have been double checked are automatically added to the analyses within this dashboard. This facilitates regular updates. 

The manuscript of the base review is currently in preparation for submission. More details regarding publication will be presented on this page <br />

The R scripts and dataset will be made available via Github along with the publication of the manuscript of the base review. <br />

[click here](forms/second_round_screening_form.pdf) for the second round screening forms. <br />
[click here]() for the data extraction forms. <br />
[click here]() for the risk of bias assessment forms. <br />

For questions or comments, please contact the corresponding author via stefan.elbers@hu.nl

Column
-------------------------------------

```{r}
img = readPNG("fp_pic.png")
```


Flow Chart {data-orientation=rows}
=======================================================================

Row {data-height=1200}
-------------------------------------
### flow chart
```{r}
prisma(31894, 90, 17955, 17955, 17588, 374, 311, 63, 56)
```

Study/patient characteristics {data-orientation=rows}
=======================================================================

Row {data-height=1000}
-------------------------------------
### Study and patient characteristics

```{r}
#create table 1 with reactable
reactable(t1,
          columns = list(
            "author (year)" = colDef(minWidth = 105),
            cohort_id = colDef(maxWidth = 30, name = "ID"),
            "cohort name" = colDef(minWidth = 105),
            "study sample size" = colDef(format = colFormat(digits = 0))
          ),
          defaultColGroup = colGroup(headerClass = "header"),
          style = list(fontFamily = "Arial Narrow", fontSize = "14px"),
          columnGroups = list(
            colGroup(name = "sample size", columns = sample_cols),
            colGroup(name = "patient characteristics", columns = patient_cols)
          ),
          defaultColDef = colDef(
            header = function(value) gsub("_", " ", value, fixed = TRUE),
            cell = function(value) format(value),
            align = "left",
            minWidth = 70
            ),
          searchable = TRUE,
          showPageSizeOptions = TRUE
          )
          
```

Intervention characteristics {data-orientation=rows}
=======================================================================

Row {data-height=1000}
-------------------------------------
### table intervention characteristics

```{r}
#create table 2 with reactable
reactable(t2,
          defaultSorted = "author_year",
          defaultSortOrder = "asc",
          defaultColGroup = colGroup(headerClass = "header"),
          style = list(fontFamily = "Arial Narrow", fontSize = "14px"),
          columnGroups = list(
            colGroup(name = "Treatment modalities", columns = procedure_cols),
            colGroup(name = "Healthcare providers", columns = hcp_cols)
            ),
          defaultColDef = colDef(
            header = function(value) gsub("_", " ", value, fixed = TRUE),
            cell = function(value) format(value, nsmall = 1),
            align = "left",
            minWidth = 70,
            headerStyle = list(background = "#f7f7f8")
            ),
          columns = list(
            author_year = colDef(minWidth = 105),
            other_procedures = colDef(minWidth = 200),
            other_healthcare_providers = colDef(minWidth = 110),
            followup_sessions_description = colDef(minWidth = 150),
            cohort_id = colDef(maxWidth = 30, name = "ID"),
            ed = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
              }, style = function(value){
                if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
                list(background = color)
              }),
            ex = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
              }),
            ga = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            ph = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            wo = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            bt = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            pm = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            ba = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            te = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            re = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            phy = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            psy = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            pt = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            ot = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            nur = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            }),
            swo = colDef(maxWidth = 30, cell = function(value) {
              # Render as ✘ or ✓
              if (value == 0) "\u2718" else "\u2713"
            }, style = function(value){
              if (value == 0) {color <- '#ABB2B9'} else {color <- '#28B463'}
              list(background = color)
            })
          ),
          bordered = FALSE,
          highlight = FALSE,
          striped = FALSE,
          searchable = TRUE,
          showPageSizeOptions = TRUE,
          onClick = "expand"
          )
```

Time Series {data-orientation=rows}
=======================================================================

Row {data-height=600 .tabset .tabset-fade}
-------------------------------------

### Pain interference

```{r timeseries pain interference}
#subset dataset with measurements on pain_interference

dat_pinter <- dat_clean %>%
    dplyr::filter(measurements_pain_interference == "yes")

#create dataframe for mean values over time  
ts_m <- select (dat_pinter, cohort, author, year, cohort_id, pinter_pre_m, pinter_post_m, pinter_fu1_m,
                  pinter_fu2_m, pinter_fu3_m, measurements_pain_interference, pinter_name_measurement_instrument) %>%
  rename(instrument_name = pinter_name_measurement_instrument, 
         pre_m = pinter_pre_m,
         post_m = pinter_post_m,
         fu1_m = pinter_fu1_m,
         fu2_m = pinter_fu2_m,
         fu3_m = pinter_fu3_m,
         instrument_present = measurements_pain_interference)

#create dataframe for SD values over time and change columns to numeric  
ts_sd <- select (dat_pinter, cohort, pinter_pre_sd, pinter_post_sd, pinter_fu1_sd,
                 pinter_fu2_sd, pinter_fu3_sd) %>%
  rename( pre_sd = pinter_pre_sd,
          post_sd = pinter_post_sd,
          fu1_sd = pinter_fu1_sd,
          fu2_sd = pinter_fu2_sd,
          fu3_sd = pinter_fu3_sd)

cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)

#create dataframe for time and add pre/post values  
ts_t <- select (dat_pinter, cohort, pinter_fu1_t, pinter_fu2_t, pinter_fu3_t) %>%
  rename( fu1_t = pinter_fu1_t,
          fu2_t = pinter_fu2_t,
          fu3_t = pinter_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring
ts_long$rev_score_m <- (ts_long$max_scale)-ts_long$m 

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "rev_score_m"]
  }
}

#standardize mean
ts_long$m_stand = ((ts_long$m_final-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_stand, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_stand
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_stand),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Pain intensity

```{r time series: pain intensity}
#subset dataset with measurements on pain_interference

dat_pintens <- dat_clean %>%
    filter(measurements_pain_intensity == "yes")  

#create dataframe for mean values over time    
  ts_m <- select (dat_pintens, cohort, author, year, cohort_id, pintens_pre_m, pintens_post_m, pintens_fu1_m,
                  pintens_fu2_m, pintens_fu3_m, measurements_pain_intensity, pintens_name_measurement_instrument) %>%
    rename(instrument_name = pintens_name_measurement_instrument, 
           pre_m = pintens_pre_m,
           post_m = pintens_post_m,
           fu1_m = pintens_fu1_m,
           fu2_m = pintens_fu2_m,
           fu3_m = pintens_fu3_m,
           instrument_present = measurements_pain_intensity)
  
  #create dataframe for SD values over time and change columns to numeric  
    ts_sd <- select (dat_pintens, cohort, pintens_pre_sd, pintens_post_sd, pintens_fu1_sd,
                   pintens_fu2_sd, pintens_fu3_sd) %>%
    rename( pre_sd = pintens_pre_sd,
            post_sd = pintens_post_sd,
            fu1_sd = pintens_fu1_sd,
            fu2_sd = pintens_fu2_sd,
            fu3_sd = pintens_fu3_sd)
  
    cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
    ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
    
#create dataframe for time and add pre/post values   
     ts_t <- select (dat_pintens, cohort, pintens_fu1_t, pintens_fu2_t, pintens_fu3_t) %>%
    rename( fu1_t = pintens_fu1_t,
            fu2_t = pintens_fu2_t,
            fu3_t = pintens_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Physical function

```{r}
#subset dataset with measurements on pain_interference

dat_pf <- dat_clean %>%
    dplyr::filter(measurements_physical_functioning == "yes")
  
#create dataframe for mean values over time 
  ts_m <- select (dat_pf, cohort, author, year, cohort_id, pf_pre_m, pf_post_m, pf_fu1_m,
                  pf_fu2_m, pf_fu3_m, measurements_physical_functioning, pf_measurement_name) %>%
    rename(instrument_name = pf_measurement_name, 
           pre_m = pf_pre_m,
           post_m = pf_post_m,
           fu1_m = pf_fu1_m,
           fu2_m = pf_fu2_m,
           fu3_m = pf_fu3_m,
           instrument_present = measurements_physical_functioning)

#create dataframe for SD values over time and change columns to numeric    
  ts_sd <- select (dat_pf, cohort, pf_pre_sd, pf_post_sd, pf_fu1_sd,
                   pf_fu2_sd, pf_fu3_sd) %>%
    rename( pre_sd = pf_pre_sd,
            post_sd = pf_post_sd,
            fu1_sd = pf_fu1_sd,
            fu2_sd = pf_fu2_sd,
            fu3_sd = pf_fu3_sd)
  
cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
  
#create dataframe for time and add pre/post values 
ts_t <- select (dat_pf, cohort, pf_fu1_t, pf_fu2_t, pf_fu3_t) %>%
    rename( fu1_t = pf_fu1_t,
            fu2_t = pf_fu2_t,
            fu3_t = pf_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Depression

```{r}
#subset dataset with measurements on depression

dat_dep <- dat_clean %>%
  dplyr::filter(measurements_depression == "yes")  

#create dataframe for mean values over time    
ts_m <- select (dat_dep, cohort, author, year, cohort_id, dep_pre_m, dep_post_m, dep_fu1_m,
                dep_fu2_m, dep_fu3_m, measurements_depression, dep_name_measurement_instrument) %>%
  rename(instrument_name = dep_name_measurement_instrument, 
         pre_m = dep_pre_m,
         post_m = dep_post_m,
         fu1_m = dep_fu1_m,
         fu2_m = dep_fu2_m,
         fu3_m = dep_fu3_m,
         instrument_present = measurements_depression)
 
#create dataframe for SD values over time and change columns to numeric   
ts_sd <- select (dat_dep, cohort, dep_pre_sd, dep_post_sd, dep_fu1_sd,
                 dep_fu2_sd, dep_fu3_sd) %>%
  rename( pre_sd = dep_pre_sd,
          post_sd = dep_post_sd,
          fu1_sd = dep_fu1_sd,
          fu2_sd = dep_fu2_sd,
          fu3_sd = dep_fu3_sd)

cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)

#create dataframe for time and add pre/post values  
ts_t <- select (dat_dep, cohort, dep_fu1_t, dep_fu2_t, dep_fu3_t) %>%
  rename( fu1_t = dep_fu1_t,
          fu2_t = dep_fu2_t,
          fu3_t = dep_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 

```

### Anxiety

```{r}
#subset dataset with measurements on anxiety

dat_anx <- dat_clean %>%
    dplyr::filter(measurements_anxiety == "yes")  

#create dataframe for mean values over time   
  ts_m <- select (dat_anx, cohort, author, year, cohort_id, anx_pre_m, anx_post_m, anx_fu1_m,
                  anx_fu2_m, anx_fu3_m, measurements_anxiety, anx_name_measurement_instrument) %>%
    rename(instrument_name = anx_name_measurement_instrument, 
           pre_m = anx_pre_m,
           post_m = anx_post_m,
           fu1_m = anx_fu1_m,
           fu2_m = anx_fu2_m,
           fu3_m = anx_fu3_m,
           instrument_present = measurements_anxiety)
 
#create dataframe for SD values over time and change columns to numeric  
  ts_sd <- select (dat_anx, cohort, anx_pre_sd, anx_post_sd, anx_fu1_sd,
                   anx_fu2_sd, anx_fu3_sd) %>%
    rename( pre_sd = anx_pre_sd,
            post_sd = anx_post_sd,
            fu1_sd = anx_fu1_sd,
            fu2_sd = anx_fu2_sd,
            fu3_sd = anx_fu3_sd)
  
  cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
  ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
  
  #create dataframe for time and add pre/post values
   ts_t <- select (dat_anx, cohort, anx_fu1_t, anx_fu2_t, anx_fu3_t) %>%
    rename( fu1_t = anx_fu1_t,
            fu2_t = anx_fu2_t,
            fu3_t = anx_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#change SD columns to numeric
cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
#sapply(ts_sd, class)


#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### General emotional functioning

```{r}
#subset dataset with measurements on pain_interference

dat_ef <- dat_clean %>%
    dplyr::filter(measurements_general_emotional_functioning == "yes")  

#create dataframe for mean values over time    
  ts_m <- select (dat_ef, cohort, author, year, cohort_id, ef_pre_m, ef_post_m, ef_fu1_m,
                  ef_fu2_m, ef_fu3_m, measurements_general_emotional_functioning, ef_name_measurement_instrument) %>%
    rename(instrument_name = ef_name_measurement_instrument, 
           pre_m = ef_pre_m,
           post_m = ef_post_m,
           fu1_m = ef_fu1_m,
           fu2_m = ef_fu2_m,
           fu3_m = ef_fu3_m,
           instrument_present = measurements_general_emotional_functioning)

  #create dataframe for SD values over time and change columns to numeric    
  ts_sd <- select (dat_ef, cohort, ef_pre_sd, ef_post_sd, ef_fu1_sd,
                   ef_fu2_sd, ef_fu3_sd) %>%
    rename( pre_sd = ef_pre_sd,
            post_sd = ef_post_sd,
            fu1_sd = ef_fu1_sd,
            fu2_sd = ef_fu2_sd,
            fu3_sd = ef_fu3_sd)
 
  cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
  ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
  
  #create dataframe for time and add pre/post values  
  ts_t <- select (dat_ef, cohort, ef_fu1_t, ef_fu2_t, ef_fu3_t) %>%
    rename( fu1_t = ef_fu1_t,
            fu2_t = ef_fu2_t,
            fu3_t = ef_fu3_t)
  
ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Anger

```{r}
#subset dataset with measurements on pain_interference

dat_ang <- dat_clean %>%
    dplyr::filter(measurements_anger == "yes")  

#create dataframe for mean values over time    
  ts_m <- select (dat_ang, cohort, author, year, cohort_id, ang_pre_m, ang_post_m, ang_fu1_m,
                  ang_fu2_m, ang_fu3_m, measurements_anger, ang_name_measurement_instrument) %>%
    rename(instrument_name = ang_name_measurement_instrument, 
           pre_m = ang_pre_m,
           post_m = ang_post_m,
           fu1_m = ang_fu1_m,
           fu2_m = ang_fu2_m,
           fu3_m = ang_fu3_m,
           instrument_present = measurements_anger)
  
#create dataframe for SD values over time and change columns to numeric   
  ts_sd <- select (dat_ang, cohort, ang_pre_sd, ang_post_sd, ang_fu1_sd,
                   ang_fu2_sd, ang_fu3_sd) %>%
    rename( pre_sd = ang_pre_sd,
            post_sd = ang_post_sd,
            fu1_sd = ang_fu1_sd,
            fu2_sd = ang_fu2_sd,
            fu3_sd = ang_fu3_sd)

#create dataframe for time and add pre/post values 
ts_t <- select (dat_ang, cohort, ang_fu1_t, ang_fu2_t, ang_fu3_t) %>%
    rename( fu1_t = ang_fu1_t,
            fu2_t = ang_fu2_t,
            fu3_t = ang_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Social role functioning

```{r}
#subset dataset with measurements on pain_interference

dat_srf <- dat_clean %>%
    dplyr::filter(measurements_social_role_functioning == "yes")  

#create dataframe for mean values over time    
  ts_m <- select (dat_srf, cohort, author, year, cohort_id, srf_pre_m, srf_post_m, srf_fu1_m,
                  srf_fu2_m, srf_fu3_m, measurements_social_role_functioning, srf_name_measurement_instrument) %>%
    rename(instrument_name = srf_name_measurement_instrument, 
           pre_m = srf_pre_m,
           post_m = srf_post_m,
           fu1_m = srf_fu1_m,
           fu2_m = srf_fu2_m,
           fu3_m = srf_fu3_m
           )

  #create dataframe for SD values over time and change columns to numeric   
  ts_sd <- select (dat_srf, cohort, srf_pre_sd, srf_post_sd, srf_fu1_sd,
                   srf_fu2_sd, srf_fu3_sd) %>%
    rename( pre_sd = srf_pre_sd,
            post_sd = srf_post_sd,
            fu1_sd = srf_fu1_sd,
            fu2_sd = srf_fu2_sd,
            fu3_sd = srf_fu3_sd)

  cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
  ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
  
#create dataframe for time and add pre/post values   
    ts_t <- select (dat_srf, cohort, srf_fu1_t, srf_fu2_t, srf_fu3_t) %>%
    rename( fu1_t = srf_fu1_t,
            fu2_t = srf_fu2_t,
            fu3_t = srf_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

### Self-efficacy

```{r}
#subset dataset with measurements on pain_interference

dat_se <- dat_clean %>%
    dplyr::filter(measurements_self_efficacy == "yes")  
  
#create dataframe for mean values over time  
  ts_m <- select (dat_se, cohort, author, year, cohort_id, se_pre_m, se_post_m, se_fu1_m,
                  se_fu2_m, se_fu3_m, measurements_self_efficacy, se_name_measurement_instrument) %>%
    rename(instrument_name = se_name_measurement_instrument, 
           pre_m = se_pre_m,
           post_m = se_post_m,
           fu1_m = se_fu1_m,
           fu2_m = se_fu2_m,
           fu3_m = se_fu3_m,
           instrument_present = measurements_self_efficacy)

#create dataframe for SD values over time and change columns to numeric   
  ts_sd <- select (dat_se, cohort, se_pre_sd, se_post_sd, se_fu1_sd,
                   se_fu2_sd, se_fu3_sd) %>%
    rename( pre_sd = se_pre_sd,
            post_sd = se_post_sd,
            fu1_sd = se_fu1_sd,
            fu2_sd = se_fu2_sd,
            fu3_sd = se_fu3_sd)

cols.num <- c("pre_sd","post_sd", "fu1_sd", "fu2_sd", "fu3_sd")
ts_sd[cols.num] <- sapply(ts_sd[cols.num],as.numeric)
  
#create dataframe for time and add pre/post values   
ts_t <- select (dat_se, cohort, se_fu1_t, se_fu2_t, se_fu3_t) %>%
rename( fu1_t = se_fu1_t,
        fu2_t = se_fu2_t,
        fu3_t = se_fu3_t)

ts_t$pre_t = -5
ts_t$post_t = 0

#convert to long dataset
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
ts_m_long <- pivot_longer(ts_m, 
                          cols = c("pre_m", "post_m", "fu1_m", "fu2_m", "fu2_m", "fu3_m"),
                          names_to = "timepoint",
                          values_to = "m")

ts_sd_long <- pivot_longer(ts_sd, 
                           cols = c("pre_sd", "post_sd", "fu1_sd", "fu2_sd", "fu2_sd", "fu3_sd"),
                           names_to = "timepoint",
                           values_to = "sd")

ts_t_long <- pivot_longer(ts_t,
                          cols = c("pre_t", "post_t", "fu1_t", "fu2_t", "fu3_t"),
                          names_to = "timepoint",
                          values_to = "t")

#merge long datasets
ts_sd_long$timepoint <-  gsub("\\_sd*$","",ts_sd_long$timepoint)
ts_t_long$timepoint <- gsub("\\_t*$","",ts_t_long$timepoint)
ts_m_long$timepoint <- gsub("\\_m*$","",ts_m_long$timepoint)

ts_sdt_long <- merge(ts_sd_long, ts_t_long, c("cohort", "timepoint"))
ts_long <- merge(ts_sdt_long, ts_m_long, c("cohort", "timepoint"))

#create max_score column
ts_long$max_scale <- as.numeric(questionnaires$max_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create min_score column
ts_long$min_scale <- as.numeric(questionnaires$min_scale)[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#create reverse scoring variable
ts_long$rev_score <- questionnaires$reverse_scoring[match(as.character(ts_long$instrument_name), as.character(questionnaires$q))]

#reverse scoring and standardizing, using the following principle: distance between the mean score and the unfavorable end of the scale divided by the total scale distance, multiplied by 100.
ts_long$m_rev_stand <- (ts_long$max_scale-ts_long$m)/(ts_long$max_scale-ts_long$min_scale)*100

#standardize mean for data that does not have to be reversed
ts_long$m_stand = ((ts_long$m-ts_long$min_scale)/(ts_long$max_scale-ts_long$min_scale))*100

#combining rev_score and normal score on contion of ts_long$rev_score

ts_long$m_final <- ts_long$m_stand

for (row in 1:nrow(ts_long)) {
  if (ts_long[row, "rev_score"] == 1 & !is.na(ts_long[row, "rev_score"])) {
    # replace value by ts_long$rev_score_m
    ts_long[row, "m_final"] <- ts_long[row, "m_rev_stand"]
  }
}

#create plot
p <- ggplot(ts_long, aes(x=t, y=m_final, group=cohort, color=cohort, text = 
                           paste("Author: ", author,
                                 "<br>Year: ", year,
                                 "<br>Cohort ID: ", cohort_id,
                                 "<br>Instrument: ", instrument_name,
                                 "<br>Raw mean: ", m,
                                 "<br>Raw SD: ", sd,
                                 "<br>Standardized score ", m_final
                           ))) +
  labs(y= "outcome standardized (0-100)") +
  geom_line(data=ts_long[!is.na(ts_long$m_final),]) + 
  geom_point() +
  scale_x_continuous(name = "Time (months)",
                     breaks = c(-5, 0, 3, 6, 12, 24, 60, 120),
                     labels = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
                     limits = c(-5, 200))

ggplotly(p, tooltip = "text") %>%
  layout(
    xaxis = list(
      tickvals = c(-5, 0, 3, 6, 12, 24, 60, 120),
      ticktext = c("pre", "post", "3m", "6m", "12m", "24m", "60m", "120m"),
      ticklen = 5,
      tickwidth = 2,
      tickcolor = toRGB("blue"),
      breaks = c(-7, 26),
      range=c(-7, 26)
    ),
    yaxis = list(
      range=c(0, 100))
  ) 
```

Row {data-height=100}
-------------------------------------
Interactive timeseries with scores on a standardized scale that represents the scoring percentage on each respective measurement instrument. Standardization was applied using the following formula: [distance between value and unfavorable end of the scale]/[total distance of the scale]*100. <br />

We also applied reverse scoring to ensure that higher scores indicate improved functioning or wellbeing. <br />


<br /> **Instructions for use:** <br />
1. Each outcome is displayed under a different tab. <br />
2. hovering over a timepoint will reveal the raw scores, standard deviation, cohort information and used measurement instrument. <br />
3. You can navigate the mouse to the upper right corner of the plot to zoom, autoscale, select or print the graph. <br />
4. It is possible to select or deselect each cohort, by clicking on the line in the table legend. If you double click on the line, you can   
   isolate that particular cohort.

Forest Plots {data-orientation=rows}
=======================================================================

Row {.sidebar}
-----------------------------------------------------------------------

```{r}
sliderInput(inputId = "r_value",
                label = "R Correction Value:",
                min = 0,
                max = 1,
                step = 0.1,
                value = .5)

selectInput(inputId = "outcome",
                label = "select ouctome:",
                choices = c("health related quality of life", "physical function", "pain interference", "depression", "anxiety",   
                            "self-efficacy", "social functioning", "pain intensity", "anger", "general emotional functioning"),
                selected = "pain interference")
        
selectInput(inputId = "contrast",
                label = "select contrast:",
                choices = c("pre-post", "post-fu", "pre-fu"),
                selected = "pre-post")
```


Row {data-height=1000}
-------------------------------------

### Shiny forest plots

```{r}
## create shinyapp ##
renderPlot({
    
    data_fp$ri <- input$r_value
    data_fp_meta <- escalc(measure="SMCR", m1i=right_m, m2i=left_m, sd1i=left_sd, ni=right_n, ri=ri, data=data_fp)
    fp_meta <- metafor::summary.escalc(data_fp_meta)
    fp_meta2 <- filter(fp_meta, contrast == input$contrast & outcome == input$outcome)
    fp_meta2$tabletext <- cbind(fp_meta2$author, fp_meta2$year, fp_meta2$right_n, fp_meta2$name_measurement_instrument, 
                                fp_meta2$fu_month)
    
    forestplot(fp_meta2$tabletext, fp_meta2$yi, fp_meta2$ci.lb, fp_meta2$ci.ub,
               xlab = "<---favors pre---     ---favors post--->",
               txt_gp=fpTxtGp(label=gpar(cex=1),
                              ticks=gpar(cex=.6),
                              xlab=gpar(cex = 1),
                              title=gpar(cex = 1.1)),
               col=fpColors(box="black", lines="black", zero = "gray50"),
               zero=0, cex=0.5, lineheight = unit(1, "cm"), boxsize=0.3,
               lwd.ci=2, ci.vertices=TRUE, ci.vertices.height = .1, grid=TRUE,
               align = "l",
               graph.pos = "right",
               clip = c(-4, 4),
               alim = c(-4,4)
    ) 
  })

```

Risk of Bias forms {data-orientation=rows}
=======================================================================

Row {data-height=1200}
-------------------------------------

### Risk of Bias

```{r}
#create table
t_rob2 <- select(dat_rob, `study id`, author, year, 6:17)

reactable(t_rob2,
          defaultSorted = "author",
          defaultSortOrder = "asc",
          defaultColGroup = colGroup(headerClass = "header"),
          style = list(fontFamily = "Arial Narrow", fontSize = "14px"),
          defaultColDef = colDef(
            header = function(value) gsub("_", " ", value, fixed = TRUE),
            cell = function(value) format(value, nsmall = 0),
            align = "left",
            minWidth = 70,
            headerStyle = list(background = "#f7f7f8")
          ),
          columns = list(
            `study id` = colDef(minWidth = 50),
            author = colDef(minWidth = 80),
            year = colDef(minWidth = 50)
          ),
          bordered = FALSE,
          highlight = FALSE,
          striped = FALSE,
          searchable = TRUE,
          showPageSizeOptions = TRUE,
          onClick = "expand"
)
```


Data extraction forms {data-orientation=columns}
=======================================================================


row {.sidebar}
-----------------------------------------------------------------------

```{r}
selectInput(inputId = "author",
                  label = "select author:",
                  choices = author_list,
                  selected = NULL)
```

row
-------------------------------------

```{r}
renderFormattable({
    extraction_data <- as.data.frame(t(dplyr::filter(dat_clean, author == input$author)))
    formattable(extraction_data)  
})
```


******** load_packages.R ********
# Package names
packages <- c("data.table", "DiagrammeR", "dplyr", "DT", "flexdashboard", "forestplot", "formattable", 
              "gsheet", "htmltools", "Hmisc" , "lessR", "magrittr", "meta", "metafor", "plotly", "png", "PRISMAstatement", 
              "psych", "reactable", "readxl", "rsconnect", "shiny", "stringr", "summarytools", "tidyr", "tidyverse", "wesanderson", "rlang", "DescTools", "dmetar", "readr" )

# This code chunk simply makes sure that all the libraries used here are installed, it will not be shown in the report (notice echo = FALSE).
if ( length(missing_pkgs <- setdiff(packages, rownames(installed.packages()))) > 0) {
  message("Installing missing package(s): ", paste(missing_pkgs, collapse = ", "))
  install.packages(missing_pkgs)
}

# Load packages
invisible(lapply(packages, library, character.only = TRUE))

******** load_data.R ********

READ FIRST: you will first have to insert the URL from your dataset

# paste code below in markdown file stead of the code chunk, but load_data.R file should be located in the online environment under "~/R/..."
#source("R/load_data.R")


#Input
url <- '[ENTER here your gsheet URL to your data extraction sheets]'
url_rob <- '[ENTER here your gsheet URL to your risk of bias extraction sheets]' 


##read main dataset
dat_gsheet <- gsheet2tbl(url) # keep dat_gsheet as in Google Sheets
dat <- dat_gsheet # We'll continue with dataset in variable 'dat'

dat_clean <- dat %>%
  dplyr::filter(!is.na(author) & !author == "test" & !author == 0)

## create cohort variable
dat_clean$cohort <- paste(dat_clean$author, dat_clean$year, dat_clean$cohort_id, sep = "_")

##clean dataset
dat_clean[dat_clean=="na"] <- NA
dat_clean[dat_clean=="Yes"] <- "yes"
dat_clean[dat_clean=="No"] <- "no"

##check assessor names
unique(dat_clean$assessor)

##filter on double checked entries
dat_clean <- dat_clean %>% dplyr::filter(assessor == "SKSE" | assessor == "SEMK" | assessor == "UKSE" | assessor == "UKMK")

#ROB dataset

##read ROB data
dat_rob <- gsheet2tbl(url_rob)

## filter double checked entries
dat_rob <- dat_rob %>% dplyr::filter(assessor == "SKSE" | assessor == "SEMK")

## filter double checked entries
dat_rob <- dat_rob %>% dplyr::filter(assessor == "SKSE" | assessor == "SEMK")

##check double entries
table(dat_rob$`study id`)
table(dat_rob$author)
table(dat_rob$year)

#create list of authors
author_list <- (dat$author) %>%
  as.data.frame() %>%
  unique() 

******** Questionnaires dataframe ********

#install.packages
#install.packages("prob")

#load packages
#library(magrittr)
#library(prob)

#create dataframe for all included questionnaires
#Use dataframe as follows: df$max_scale <- questionnaires$q[match(as.character(df$instrument_name), as.numeric(questionnaires$max_scale))]

questionnaires <- structure(list(V1 = c("VAS", "VAS (0-100)", "PRI", "MPI: pain severity (0-6)"),
                                 V2 = c(0, 0, 0, 0),
                                 V3 = c(100, 100, 78, 6),
                                 V4 = c(1, 1, 1, 1)), 
                                 .Names = c("q", "min_scale", "max_scale", "reverse_scoring"), 
                                 class = "data.frame",
                                 row.names = c(NA, -4L))


#V4: if higher scores indicate better functioning, no reverse scoring (0), if lower scores indicate better functioning, reverse scoring (1)


#add additional questionnaires. c1: instrument name on google forms; c2: min_scale; c3 max_scale; c4 reverse_scoring
questionnaires <- questionnaires %>%
  rbind(
    vector_nrs <- c("NRS", 0, 10, 1),            
    vector_nprs <- c("NPRS", 0, 10, 1),
    vector_nrs010 <- c("NRS (0-10)", 0, 10, 1),
    vector_VAS010 <- c("VAS (0-10)", 0, 10, 1),
    vector_NRS0100 <- c("NRS (0-100)", 0, 100, 1),
    vector_likert_pintens <- c("Likert pain intensity", 0, 6, 1),
    vector_rdq <- c("RDQ", 0, 24, 1),
    vector_QBPDS <- c("QBPDS", 0, 100, 1),
    vector_LBPRS <- c("LBPRS", 0, 30, 1),
    vector_DRI <- c("DRI", 0, 1200, 1),
    vector_DRI0100 <- c("DRI (0-100)", 0, 100, 1),
    vector_MPI_PI <- c("MPI: pain interference (0-6)", 0, 6, 1),
    vector_MPI_PI_012 <- c("MPI: pain interference (0-12)", 0, 12, 1),
    vector_MPI_PS_012 <- c("MPI: pain severity (0-12)", 0, 12, 1),
    vector_ODI <- c("ODI", 0, 100, 1),
    vector_ODI01 <- c("ODI (0-1)", 0, 1, 1),
    vector_PDI <- c("PDI", 0, 70, 1),
    vector_RMDQ <- c("RMDQ", 0, 24, 1),
    vector_DPQ_da <- c("DPQ: Daily activities", 0, 100, 1),
    vector_sf36_pf <- c("SF-36 subscale Physical Functioning", 0, 100, 0),
    vector_NHP_pa <- c("NHP: PA", 0, 100, 1),
    vector_hfaq <- c("HFAQ", 0, 100, 0),
    vector_mpi_ga_06 <- c("MPI: GA (0-6)", 0, 6, 0),
    vector_norfunk <- c("Norfunk (0-3)", 0, 3, 1),
    vector_ADS <- c("ADS (german scale of CES-D)", 0, 60, 1),
    vector_haDs <- c("HADS-D", 0, 21, 1),
    vector_dass <- c("DASS", 0, 42, 1),
    vector_bdi2 <- c("BDI-II", 0, 63, 1),
    vector_zung <- c("Zung", 0, 100, 1),
    vector_bdi <- c("BDI", 0, 63, 1),
    vector_deps <- c("Depression index (DEPS)", 0, 30, 1),
    vector_scl90d <- c("SCL90-D", 0, 52, 1),
    vector_hAds <- c("HADS-A", 0, 21, 1),
    vector_vas_a <- c("VAS Anxiety (0-100)", 0, 100, 1),
    vector_scl90a <- c("SCL90-A", 0, 40, 1),
    vector_stai <- c("STAI", 20, 80, 1),
    vector_fri <- c("FRI", 0, 100, 1),
    vector_nhp_er <- c("NHP: Emotional reactions", 0, 100, 1),
    vector_sf36mh <- c("SF-36: mental health", 0, 100, 0),
    vector_MPI_di_012 <- c("MPI: distress (0-12)", 0, 12, 1),
    vector_dpq_ad <- c("DPQ: anxiety/depression", 0, 100, 1),
    vector_scl90h <- c("SCL-90: Hostility", 0, 24, 1),
    vector_pseq <- c("PSEQ", 0, 60, 0),
    vector_dpq_sl <- c("DPQ: social life", 0, 100, 1),
    vector_sf36_sf <- c("SF-36: social functioning", 0, 100, 0),
    vector_sip <- c("SIP", 0, 9608, 1),
    vector_qbprs <- c("QBPRS", 0, 100, 1),
    vector_euroq_vas <- c("EuroQol-5D-3L (VAS 0-100)", 0, 100, 0),
    vector_mean_nhp <- c("mean NHP (0-100)", 0, 100, 1),
    vector_german_lsq <- c("German Life Satisfaction Questionnaire (higher is better)", 7, 49, 0),
    vector_fiq <- c("FIQ (0-100)", 0, 100, 1),
    vector_whoqol_bref <- c("WHOQOL-BREF: global (0-100)", 0, 100, 0),
    vector_lisat11 <- c("LiSat-11: life a a whole (1-6)", 1, 6, 0),
    vector_comi_pain <- c("COMI: pain (0-10)", 0, 10, 1),
    vector_comi_function <- c("COMI: function (0-10)", 0, 10, 1),
    vector_rand_pf <- c("RAND-36 subscale Physical Functioning", 0, 100, 0),
    vector_dass_anx <- c("DASS: anxiety", 0, 42, 1),
    vector_mpi0_pi_0100 <- c("MPI: pain interference (0-100)", 0, 100, 1),
    vector_GSE <- c("GSE (1-4)", 1, 4, 0),
    vector_DSkala <- c("DS (depressivitats-skala)", 0, 48, 1),
    vector_MPI_di_06 <- c("MPI: distress (0-6)", 0, 6, 1)
    )


#merge additional questionnaires to main set

i_hrqol <- as.tibble(unique(dat_clean$hrqol_name_measurement_instrument))
i_pf <- as.tibble(unique(dat_clean$pf_measurement_name))
i_pinter <- as.tibble(unique(dat_clean$pinter_name_measurement_instrument))
i_anx <- as.tibble(unique(dat_clean$anx_name_measurement_instrument))
i_dep <- as.tibble(unique(dat_clean$dep_name_measurement_instrument))
i_ef <- as.tibble(unique(dat_clean$ef_name_measurement_instrument))
i_ang <- as.tibble(unique(dat_clean$ang_name_measurement_instrument))
i_se <- as.tibble(unique(dat_clean$se_name_measurement_instrument))
i_srf <- as.tibble(unique(dat_clean$srf_name_measurement_instrument))
i_pintens <- as.tibble(unique(dat_clean$pintens_name_measurement_instrument))

i_total <- rbind(i_hrqol, i_pf, i_pinter, i_anx, i_dep, i_ef, i_ang, i_se, i_srf, i_pintens) %>% na.omit

#check if all questionnaires are present in questionnaires dataframe
i_total[!i_total$value %in% questionnaires$q,  ]
                            
******** Shiny fp prep md ********

#preparation R script for Shiny forest plots

dat <- dat_clean %>%
  rename(pf_name_measurement_instrument = pf_measurement_name,
         meas_hrqol = measurement_of_hrqol,
         meas_pf = measurements_physical_functioning,
         meas_pinter = measurements_pain_interference,
         meas_dep = measurements_depression,
         meas_anx = measurements_anxiety,
         meas_ef = measurements_general_emotional_functioning,
         meas_ang = measurements_anger,
         meas_se = measurements_self_efficacy,
         meas_srf = measurements_social_role_functioning,
         meas_pintens = measurements_pain_intensity)

# create variables 
dat$char_age_sd <- as.character(dat$age_sd)
dat$char_age_m <- as.character(dat$age_m)
dat$char_age_sd <- paste("(", dat$char_age_sd, ")", sep = "")
dat$age_m_sd <- paste(dat$char_age_m, dat$char_age_sd, sep = " ")
dat$age_m_sd[dat$age_m_sd=="NA (NA)"] <- NA
dat$char_year <- paste("(", dat$year, ")", sep="")
dat$author_year <- paste(dat$author, dat$char_year, sep = " ")

#calculate attrition
dat$attrition_post <- round(100-((dat$sample_size_post/dat$sample_size_pre)*100), 2)
dat$attrition_fu <- round(100-((dat$sample_size_fu/dat$sample_size_post)*100), 2)

#create variable cohort
dat$cohort <- paste(dat$author, dat$year, dat$cohort_id, sep = "_")

#get info from study with cohort_id > 1 from same study with cohort_id = 1
copyVarsFromCohort_id1 <- c("nationality","patient_group") # TO DO: variables need to be added
for (ind1 in which(dat$cohort_id > 1)) {
  #find same study (Author,year) but with cohort_id = 1
  ind2 <- which(dat$author == dat$author[ind1] & dat$year == dat$year[ind1]  & dat$cohort_id == 1)
  for (v in copyVarsFromCohort_id1) {
    eval(parse(text=paste('dat$', v, '[', ind1, ']=dat$', v, '[', ind2, ']', sep = "")))
  }
}

# meetinstrumenten
meetinstrumenten <- c("hrqol","pf","pinter","dep","anx","ef","ang","se","srf","pintens") 

#determine last follow-up (last_fu)
for (mi in meetinstrumenten) {
  v1 <- paste(mi, '_last_fu', sep = "") 
  dat[v1] = 1 # initialise, <meetinstrument>_last_fu = 1
  
  # Was there even a second follow-up?
  v2 <- paste('meas', mi, sep = "_")
  v3 <- paste(mi, '_measurement_after_fu1', sep = "")
  ind <- which( dat[v2] == "yes" & dat[v3] == "yes" )
  dat[ind,v1] = 2
  
  # Was there even a third follow-up?
  v2 <- paste('meas', mi, sep = "_")
  v3 <- paste(mi, '_measurement_after_fu2', sep = "")
  ind <- which( dat[v2] == "yes" & dat[v3] == "yes" )
  dat[ind,v1] = 3
}

##check
#mi <- "pf"
#dat <- dat[dat$author == "Thieme",] 

#replace missing 'n' from outcomes (pre/post) with generic 'n'
for (mi in meetinstrumenten) {
  v1 <- paste('meas', mi, sep = "_")
  
  # pre/post
  for (p in c("pre","post")) {
    #if <meetinstrument>_<pre/post>_n is missing: <meetinstrument>_<pre/post>_n = sample_size_<pre/post>
    v2 <- paste(mi, p, 'n', sep = "_")
    v3 <- paste('sample_size', p, sep = "_")
    ind <- which(dat[v1] == "yes" & is.na(dat[v2]))
    if (length(ind) > 0) {
      dat[ind,v2] <- dat[ind,v3]
    }
    
    #if <meetinstrument>_<pre/post>_n is (still) missing: <meetinstrument>_<pre/post>_n = sample_size
    ind <- which(dat[v1] == "yes" & is.na(dat[v2]))
    if (length(ind) > 0) {
      dat[ind,v2] <- dat[ind,"sample_size"]
    }
    
    
  }
  
  # follow-up (try to fill missings 'n' of the last follow-up with sample_size_fu)
  for (f in 1:3) {
    v1 <- paste(mi, '_fu', f ,'_n', sep = "")
    v2 <- paste(mi, '_last_fu', sep = "")
    ind <- which( is.na(dat[v1]) & dat[v2] == f )
    dat[ind,v1] <- dat$sample_size_fu[ind]
  }
  
  # follow-up (if still missing, get the general sample_size)
  for (f in 1:3) {
    v1 <- paste(mi, '_fu', f ,'_n', sep = "")
    v2 <- paste(mi, '_last_fu', sep = "")
    ind <- which( is.na(dat[v1]) & dat[v2] == f )
    dat[ind,v1] <- dat$sample_size[ind]
  }
}

## Forest plots
contrasts <- data.frame(left = c("pre","post","pre"), right = c("post","fu","fu"))

# remove data_long if it already exists from previous run
if (exists("data_long")) {
  rm(data_long)
}

for (mi in meetinstrumenten) {
  for (i in 1:dim(contrasts)[1]) {
    contrast <- paste(contrasts$left[i], contrasts$right[i], sep="-")
    
    # add <mi>_last_fu<m/n/sd> based on <mi>_fu<last_fu>
    v1 <- paste(mi, '_last_fu', sep = "") 
    for (ind in 1:dim(dat)[1]){
      for (w in c("m","n","sd","t")) {
        v2 <- paste(mi, '_fu', dat[ind,v1], '_', w, sep="")
        v3 <- paste(mi, '_last_fu_', w, sep="")
        dat[ind,v3] <- dat[ind,v2]     
      }
    }
    
    left <- contrasts$left[i]
    right <- contrasts$right[i]
    
    # rename 'fu' to 'last_fu'
    left <- str_replace(left,"fu","last_fu")
    right <- str_replace(right,"fu","last_fu")
    
    v1 <- paste('meas', mi, sep = "_")
    v2 <- paste(mi, left, 'm', sep = "_")
    v3 <- paste(mi, right, 'm', sep = "_")
    
    logical <- dat[v1] == "yes" & !is.na(dat[v2]) & !is.na(dat[v3])
    data_fp <- dat[logical,]
    
    #data_fp <- as_tibble(data_fp)   # dit is niet nodig?
    data_fp$fu_month <- 0
    data_fp$ri <- .54
    
    v1 <- paste(mi, right, 'm', sep = "_")  # m1i ??? Klopt originele volgorde wel?? m1i=m_post, m2i=m_pre, sd1i=sd_pre, ni=n_post 
    v2 <- paste(mi, left, 'm', sep = "_") # m2i
    v3 <- paste(mi, left, 'sd', sep = "_") # sd1i
    v4 <- paste(mi, right, 'n', sep = "_") # ni
    
    data_fp <- data_fp %>%
      mutate(m1i := eval(parse(text=v1)))
    data_fp <- data_fp %>%
      mutate(m2i := eval(parse(text=v2)))
    data_fp <- data_fp %>%
      mutate(sd1i := eval(parse(text=v3)))
    data_fp <- data_fp %>%
      mutate(ni := eval(parse(text=v4)))
    
    
    
    
    
    ## make dataset to compare with Stefans Excel file
    check_var <- paste('check', mi, contrast, sep="_")
    
    v1 <- paste(mi, 'name_measurement_instrument',sep="_")
    v2 <- paste(mi, 'last_fu_t',sep="_")
    data_fp <- data_fp %>%
      mutate(name_measurement_instrument := eval(parse(text=v1)),
             fu_month := eval(parse(text=v2)))
    
    # left
    v <- paste(mi, left, 'n', sep = "_")
    data_fp <- data_fp %>% mutate(left_n := eval(parse(text=v)))
    v <- paste(mi, left, 'sd', sep = "_")
    data_fp <- data_fp %>% mutate(left_sd := eval(parse(text=v)))
    v <- paste(mi, left, 'm', sep = "_")
    data_fp <- data_fp %>% mutate(left_m := eval(parse(text=v)))
    
    # right
    v <- paste(mi, right, 'n', sep = "_")
    data_fp <- data_fp %>% mutate(right_n := eval(parse(text=v)))
    v <- paste(mi, right, 'sd', sep = "_")
    data_fp <- data_fp %>% mutate(right_sd := eval(parse(text=v)))
    v <- paste(mi, right, 'm', sep = "_")
    data_fp <- data_fp %>% mutate(right_m := eval(parse(text=v)))
    
    data_fp_sub <- data_fp %>%
      select(author, year, cohort_id, cohort_name, name_measurement_instrument, fu_month, left_m, left_sd, left_n, right_m, right_sd, right_n)
    
    # change 1 or 2 into "a" or "b"
    data_fp_sub$cohort_id <-letters[data_fp_sub$cohort_id]
    
    # add column with contrast in first column
    data_fp_sub <- add_column(data_fp_sub, contrast = contrast, .before = 1)
    
    # add column with outcome in first column
    data_fp_sub <- add_column(data_fp_sub, outcome = mi, .before = 1)
    
    # now we can compare the data in e.g. 'check_hrqol_pre-post' with Stefans Excel-sheet
    assign(check_var,data_fp_sub)
    
    ## Eerst had ik de code gemaakt om de verschillende forester plots te maken, later bleek dat je graag de tabel in 'long format' wilde,
    ## daarom zit dat er nu op deze manier in. Achteraf gezien had dit gedaan kunnen worden voordat je de forestplots gaat maken.
    
    # combine all 'check_'-variable into one 'long format' 
    ifelse(exists("data_long"), 
           data_long <- rbind(data_long,data_fp_sub),
           data_long <- data_fp_sub)
    
  }
}


# reversed scoring. Reverse the contrast in case higher scores indicate decreased functioning.  
data_long$rev_scoring <- questionnaires$reverse_scoring[match(as.character(data_long$name_measurement_instrument), as.character(questionnaires$q))]

## reverse scoring procedure ##
data <- data_long
# return: new dataframe with corrected stds and means.
correct_rev_score <- function(data) {
  # Create new copy of data
  rev_corrected_data <- data.frame(data)
  
  # Iterate over each row in data
  for (row in 1:nrow(data)) {
    if (data[row, "rev_scoring"] == 1) {
      # Replace pre by post
      rev_corrected_data[row, "left_m"] <- data[row, "right_m"]
      rev_corrected_data[row, "left_sd"] <- data[row, "right_sd"]
      rev_corrected_data[row, "left_n"] <- data[row, "right_n"]
      
      # Replace post by pre
      rev_corrected_data[row, "right_m"] <- data[row, "left_m"]
      rev_corrected_data[row, "right_sd"] <- data[row, "left_sd"]
      rev_corrected_data[row, "right_n"] <- data[row, "left_n"]
    }
  }
  return(rev_corrected_data)
}
corrected_data <- correct_rev_score(data)

#rename outcomes
corrected_data$outcome <- corrected_data$outcome %>% recode(
  "hrqol" = "health related quality of life",
  "pf" = "physical function",
  "pinter" = "pain interference",
  "dep" =  "depression",
  "anx" = "anxiety",
  "ef" = "general emotional functioning",
  "ang" = "anger",
  "se" = "self-efficacy",
  "srf" = "social functioning",
  "pintens" = "pain intensity"
)

corrected_data <- corrected_data %>%
  mutate(fu_month = if_else(contrast == "pre-post", 0, fu_month))

data_fp <- as_tibble(corrected_data)

********results_analysis.R******** 
# data analysis for results section #
#first load packages and data


dat_res <- dat_clean

## study characteristics.

#create author year variable
dat_res$year <- paste("(", dat_res$year, ")", sep="")
dat_res$author_year <- paste(dat_res$author, dat_res$year, sep = " ")

#obtain number of studies and cohorts
a <- table(dat_res$number_of_cohorts)
b <-a[names(a)==2]
n_cohort <- nrow(dat_res)
n_study <- (n_cohort-b/2)

print(n_cohort)
print(n_study)

#obtain study design
dat_res_study <- dat_res %>%
  dplyr::filter(cohort_id == 1)
  
dat_res_study %>% count(study_design)

#find median/range for final follow-up
summary(dat_res$`final follow-up`)

#find studies that were not included in the meta-analsyis
missing_meta <- filter(dat_res, is.na(dat_res$`final follow-up`)) 

table(dat_res$author_year, dat_res$`final follow-up`)

#analyze sample size pre

dat_n <- dat_res %>%
  select(author, year, cohort_id, sample_size, sample_size_pre, sample_size_post, sample_size_fu)

summary(dat_n$sample_size_pre)

#calculate attrition

dat_n$attrition_post <- round(100-((dat_n$sample_size_post/dat_n$sample_size_pre)*100), 2)
dat_n$attrition_fu <- round(100-((dat_n$sample_size_fu/dat_n$sample_size_post)*100), 2)

summary(dat_n$attrition_post)
summary(dat_n$attrition_fu)

#leave out the studies that performed a complete case analysis
#this is not yet complete. We have to reassess the data before completing this point.
possible_complete_case_post <- dat_n %>%
  na.omit() %>%
  dplyr::filter(attrition_post <= 0)

possible_complete_case_fu <- dat_n %>%
  na.omit() %>%
  dplyr::filter(attrition_fu <= 0)


dat_n$f <- dat_n$attrition_post+dat_n$attrition_fu

dat_n_f <- dat_n %>%
  dplyr::filter(dat_n$f > 0)

n_studies_dropout_analysis <- nrow(dat_n_f)
print(n_studies_dropout_analysis)

summary(dat_n_f$attrition_post)
summary(dat_n_f$attrition_fu)

#analyze risk of bias 
describe(dat_rob[, c(6:16)])

table(dat_rob[, c(6:16)])
summarytools::freq(dat_rob[,c(6:16)], order = "freq")



##patient characteristics

#nationality
unique(dat_res$nationality)
non_eu <- c("Iran", "Malaysia", "Canada", "United States", "Australia", "USA")
non_west <- c("Iran", "Malaysia")

dat_res$eu <- 1
dat_res$eu[dat_res$nationality %in% non_eu] <- 0
dat_res$west <- 1
dat_res$west[dat_res$nationality %in% non_west] <- 0

summarytools::freq(dat_res$eu)
summarytools::freq(dat_res$west)

#gender, age and pain duration
psych::describe(dat_res$female_gender)
psych::describe(dat_res$age_m)
psych::describe(dat_res$pain_duration_months_m)

##intervention characteristics
psych::describe(dat_res$time_span)
psych::describe(dat_res$hours)
summarytools::freq(dat_res$in_out_patient)   
summarytools::freq(dat_res$type_of_contact)
summarytools::freq(dat_res$setting)

#describe treatment modalities
dat_mod <- dat_res %>%
  select(author, year, id, treatment_modalities)

dat_mod <- dat_mod %>%
  mutate(
    ed = str_detect(treatment_modalities, "education"),
    ex = str_detect(treatment_modalities, "exercise"),
    ga = str_detect(treatment_modalities, "graded activity"),
    ph = str_detect(treatment_modalities, "pharmacological treatment"),
    wo = str_detect(treatment_modalities, "workplace advice"),
    bt = str_detect(treatment_modalities, "behavioral therapy"),
    pm = str_detect(treatment_modalities, "pain management skills"),
    te = str_detect(treatment_modalities, "team meetings"),
    ba = str_detect(treatment_modalities, "body awareness therapy"),
    re = str_detect(treatment_modalities, "relaxation")
  )

treatment_mod_abb <- c("ed", "ex", "ga", "ph", "wo", "bt", "pm", "te", "ba", "re")

dat_mod[c(treatment_mod_abb)] <- 1*dat_mod[c(treatment_mod_abb)]
dat_mod[c(treatment_mod_abb)][is.na(dat_mod[c(treatment_mod_abb)])] <- 0

dat_mod$total <- rowSums(dat_mod[,c(5:14)])

summarytools::freq(dat_mod$ex)
summarytools::freq(dat_mod$ed)
summarytools::freq(dat_mod$ga)
summarytools::freq(dat_mod$ph)
summarytools::freq(dat_mod$wo)
summarytools::freq(dat_mod$bt)
summarytools::freq(dat_mod$pm)
summarytools::freq(dat_mod$te)
summarytools::freq(dat_mod$ba)
summarytools::freq(dat_mod$re)

psych::describe(dat_mod$total)

#describe involved hcps

dat_hcp <- dat_res %>%
  select(author, year, id, healthcare_providers, other_healthcare_providers)

dat_hcp <- dat_hcp %>%
  mutate(
    phy = str_detect(healthcare_providers, "Physician"),
    psy = str_detect(healthcare_providers, "psychologist"),
    pt = str_detect(healthcare_providers, "physical therapist"),
    ot = str_detect(healthcare_providers, "occupational therapist"),
    nur = str_detect(healthcare_providers, "nurse"),
    swo = str_detect(healthcare_providers, "social worker")
  )

hcp_abb <- c("phy", "psy", "pt", "ot", "nur", "swo")

dat_hcp[c(hcp_abb)] <- 1*dat_hcp[c(hcp_abb)]
dat_hcp[c(hcp_abb)][is.na(dat_hcp[c(hcp_abb)])] <- 0

dat_hcp$total <- rowSums(dat_hcp[,c(6:11)])

summarytools::freq(dat_hcp)


psych::describe(dat_hcp$total) 
#range is not correct: Eijk-Hustings is likely to have at least 3 hcp's; 
#Tavafian and Vendrig have additional HCPs in the 'other' section. The same is true for Olason
#therefore: range = 3-7

summarytools::freq(dat_hcp$phy)
summarytools::freq(dat_hcp$psy)
summarytools::freq(dat_hcp$pt)
summarytools::freq(dat_hcp$ot)
summarytools::freq(dat_hcp$nur)
summarytools::freq(dat_hcp$swo)


#calculate % of studies that include 'other' HCP professions

missing_hcp <- (sum(is.na(dat_hcp$other_healthcare_providers)))

total_cohorts <- nrow(dat_hcp)

#calculate percentage of studies that include other HCPs in their team
missing_hcp/total_cohorts*100


#describe follow-up and tailoring of treatment programs
dat_fu <- dat_res %>%
  select(author, year, id, followup_sessions_provided, followup_sessions_description, tailoring_mentioned_in_study, tailoring)

summarytools::freq(dat_fu$followup_sessions_provided)
summarytools::freq(dat_fu$tailoring)



*********risk_of_bias_table.R*************

#preparation
#before using this script, run the load_packages and load_data scripts.

#obtain dataset Risk of Bias

#create table
t_rob <- select(dat_rob, `study id`, author, year, 6:17)
  

reactable(t_rob,
          defaultSorted = "author",
          defaultSortOrder = "asc",
          style = list(fontFamily = "Arial Narrow", fontSize = "14px"),
          defaultColDef = colDef(
            header = function(value) gsub("_", " ", value, fixed = TRUE),
            cell = function(value) format(value, nsmall = 0),
            align = "left",
            minWidth = 70,
            headerStyle = list(background = "#f7f7f8")
          ),
          columns = list(
            `study id` = colDef(minWidth = 50),
            author = colDef(minWidth = 80),
            year = colDef(minWidth = 50)
          ),
          bordered = FALSE,
          highlight = FALSE,
          striped = FALSE,
          searchable = TRUE,
          showPageSizeOptions = TRUE,
          onClick = "expand"
)


#summary statistics ROB

rob_desc <- t_rob[4:12]

for (i in seq_along(rob_desc)) {            # 2. sequence
  print(colnames(rob_desc[i]))
  print(Freq(rob_desc[i]))
}

t_rob$author_year <- paste(t_rob$author, t_rob$year, sep = " " )

t_rob_sum <- t_rob

names(t_rob_sum)[4] <- "01. inclusion criteria"
names(t_rob_sum)[5] <- "02. measurement of condition"
names(t_rob_sum)[6] <- "03. valid methods of identification"
names(t_rob_sum)[7] <- "04. consecutive inclusion"
names(t_rob_sum)[8] <- "05. complete inclusion"
names(t_rob_sum)[9] <- "06. reporting demographics"
names(t_rob_sum)[10] <- "07. reporting clinical information"
names(t_rob_sum)[11] <- "08. outcomes reported"
names(t_rob_sum)[12] <- "09. location reported"
names(t_rob_sum)[13] <- "10. statistical analysis and dropout"
names(t_rob_sum)[14] <- "overall appraisal"

t_rob_sum[t_rob_sum=="high"] <- "no"
t_rob_sum[t_rob_sum=="low"] <- "yes"

t_rob_sum <- select(t_rob_sum, author_year, "1. inclusion criteria", "2. measurement of condition", "3. valid methods of identification",
                    "4. consecutive inclusion", "5. complete inclusion", "6. reporting demographics", "7. reporting clinical information",
                    "8. outcomes reported", "9. location reported", "10. statistical analysis and dropout", "overall appraisal")

t_rob_sum <- as.data.frame(t_rob_sum)

rob_barplot <- rob.summary(t_rob_sum, name.high = "no", name.low = "yes", name.unclear = "unclear", studies = t_rob_sum$author_year, table = TRUE)


#save rob figures to preferred EJP format (PDF  )

pdf(file='figure2.pdf', width = 45, height = 18) 
rob.summary(t_rob_sum, name.high = "no", name.low = "yes", name.unclear = "unclear", studies = t_rob_sum$author_year, table = TRUE); dev.off() 


*********shiny_forest_plot_static_analysis.R*********

#preparation R script for Shiny forest plots
#FIRST: LOAD load_data.r and questionnaires_dataframe.R

dat <- dat_clean %>%
  rename(pf_name_measurement_instrument = pf_measurement_name,
         meas_hrqol = measurement_of_hrqol,
         meas_pf = measurements_physical_functioning,
         meas_pinter = measurements_pain_interference,
         meas_dep = measurements_depression,
         meas_anx = measurements_anxiety,
         meas_ef = measurements_general_emotional_functioning,
         meas_ang = measurements_anger,
         meas_se = measurements_self_efficacy,
         meas_srf = measurements_social_role_functioning,
         meas_pintens = measurements_pain_intensity)

# create variables 
dat$char_age_sd <- as.character(dat$age_sd)
dat$char_age_m <- as.character(dat$age_m)
dat$char_age_sd <- paste("(", dat$char_age_sd, ")", sep = "")
dat$age_m_sd <- paste(dat$char_age_m, dat$char_age_sd, sep = " ")
dat$age_m_sd[dat$age_m_sd=="NA (NA)"] <- NA
dat$char_year <- paste("(", dat$year, ")", sep="")
dat$author_year <- paste(dat$author, dat$char_year, sep = " ")

#calculate attrition
dat$attrition_post <- round(100-((dat$sample_size_post/dat$sample_size_pre)*100), 2)
dat$attrition_fu <- round(100-((dat$sample_size_fu/dat$sample_size_post)*100), 2)

#create variable cohort
dat$cohort <- paste(dat$author, dat$year, dat$cohort_id, sep = "_")

#get info from study with cohort_id > 1 from same study with cohort_id = 1
copyVarsFromCohort_id1 <- c("nationality","patient_group") # TO DO: variables need to be added
for (ind1 in which(dat$cohort_id > 1)) {
  #find same study (Author,year) but with cohort_id = 1
  ind2 <- which(dat$author == dat$author[ind1] & dat$year == dat$year[ind1]  & dat$cohort_id == 1)
  for (v in copyVarsFromCohort_id1) {
    eval(parse(text=paste('dat$', v, '[', ind1, ']=dat$', v, '[', ind2, ']', sep = "")))
  }
}

# meetinstrumenten
meetinstrumenten <- c("hrqol","pf","pinter","dep","anx","ef","ang","se","srf","pintens") # TO DO: outcomes need to be added

#determine last follow-up (last_fu)
for (mi in meetinstrumenten) {
  v1 <- paste(mi, '_last_fu', sep = "") 
  dat[v1] = 1 # initialise, <meetinstrument>_last_fu = 1
  
  # Was there even a second follow-up?
  v2 <- paste('meas', mi, sep = "_")
  v3 <- paste(mi, '_measurement_after_fu1', sep = "")
  ind <- which( dat[v2] == "yes" & dat[v3] == "yes" )
  dat[ind,v1] = 2
  
  # Was there even a third follow-up?
  v2 <- paste('meas', mi, sep = "_")
  v3 <- paste(mi, '_measurement_after_fu2', sep = "")
  ind <- which( dat[v2] == "yes" & dat[v3] == "yes" )
  dat[ind,v1] = 3
}

##check
#mi <- "pf"
#dat <- dat[dat$author == "Thieme",] 

#replace missing 'n' from outcomes (pre/post) with generic 'n'
for (mi in meetinstrumenten) {
  v1 <- paste('meas', mi, sep = "_")
  
  # pre/post
  for (p in c("pre","post")) {
    #if <meetinstrument>_<pre/post>_n is missing: <meetinstrument>_<pre/post>_n = sample_size_<pre/post>
    v2 <- paste(mi, p, 'n', sep = "_")
    v3 <- paste('sample_size', p, sep = "_")
    ind <- which(dat[v1] == "yes" & is.na(dat[v2]))
    if (length(ind) > 0) {
      dat[ind,v2] <- dat[ind,v3]
    }
    
    #if <meetinstrument>_<pre/post>_n is (still) missing: <meetinstrument>_<pre/post>_n = sample_size
    ind <- which(dat[v1] == "yes" & is.na(dat[v2]))
    if (length(ind) > 0) {
      dat[ind,v2] <- dat[ind,"sample_size"]
    }
    
    
  }
  
  # follow-up (try to fill missings 'n' of the last follow-up with sample_size_fu)
  for (f in 1:3) {
    v1 <- paste(mi, '_fu', f ,'_n', sep = "")
    v2 <- paste(mi, '_last_fu', sep = "")
    ind <- which( is.na(dat[v1]) & dat[v2] == f )
    dat[ind,v1] <- dat$sample_size_fu[ind]
  }
  
  # follow-up (if still missing, get the general sample_size)
  for (f in 1:3) {
    v1 <- paste(mi, '_fu', f ,'_n', sep = "")
    v2 <- paste(mi, '_last_fu', sep = "")
    ind <- which( is.na(dat[v1]) & dat[v2] == f )
    dat[ind,v1] <- dat$sample_size[ind]
  }
}

## Forest plots
contrasts <- data.frame(left = c("pre","post","pre"), right = c("post","fu","fu"))

# remove data_long if it already exists from previous run
if (exists("data_long")) {
  rm(data_long)
}

for (mi in meetinstrumenten) {
  for (i in 1:dim(contrasts)[1]) {
    contrast <- paste(contrasts$left[i], contrasts$right[i], sep="-")
    
    # add <mi>_last_fu<m/n/sd> based on <mi>_fu<last_fu>
    v1 <- paste(mi, '_last_fu', sep = "") 
    for (ind in 1:dim(dat)[1]){
      for (w in c("m","n","sd","t")) {
        v2 <- paste(mi, '_fu', dat[ind,v1], '_', w, sep="")
        v3 <- paste(mi, '_last_fu_', w, sep="")
        dat[ind,v3] <- dat[ind,v2]     
      }
    }
    
    left <- contrasts$left[i]
    right <- contrasts$right[i]
    
    # rename 'fu' to 'last_fu'
    left <- str_replace(left,"fu","last_fu")
    right <- str_replace(right,"fu","last_fu")
    
    v1 <- paste('meas', mi, sep = "_")
    v2 <- paste(mi, left, 'm', sep = "_")
    v3 <- paste(mi, right, 'm', sep = "_")
    
    logical <- dat[v1] == "yes" & !is.na(dat[v2]) & !is.na(dat[v3])
    data_fp <- dat[logical,]
    
    #data_fp <- as_tibble(data_fp)   # dit is niet nodig?
    data_fp$fu_month <- 0
    data_fp$ri <- .54
    
    v1 <- paste(mi, right, 'm', sep = "_")  # m1i ??? Klopt originele volgorde wel?? m1i=m_post, m2i=m_pre, sd1i=sd_pre, ni=n_post 
    v2 <- paste(mi, left, 'm', sep = "_") # m2i
    v3 <- paste(mi, left, 'sd', sep = "_") # sd1i
    v4 <- paste(mi, right, 'n', sep = "_") # ni
    
    data_fp <- data_fp %>%
      mutate(m1i := eval(parse(text=v1)))
    data_fp <- data_fp %>%
      mutate(m2i := eval(parse(text=v2)))
    data_fp <- data_fp %>%
      mutate(sd1i := eval(parse(text=v3)))
    data_fp <- data_fp %>%
      mutate(ni := eval(parse(text=v4)))
    
    
    
    
    
    ## make dataset to compare with Stefans Excel file
    check_var <- paste('check', mi, contrast, sep="_")
    
    v1 <- paste(mi, 'name_measurement_instrument',sep="_")
    v2 <- paste(mi, 'last_fu_t',sep="_")
    data_fp <- data_fp %>%
      mutate(name_measurement_instrument := eval(parse(text=v1)),
             fu_month := eval(parse(text=v2)))
    
    # left
    v <- paste(mi, left, 'n', sep = "_")
    data_fp <- data_fp %>% mutate(left_n := eval(parse(text=v)))
    v <- paste(mi, left, 'sd', sep = "_")
    data_fp <- data_fp %>% mutate(left_sd := eval(parse(text=v)))
    v <- paste(mi, left, 'm', sep = "_")
    data_fp <- data_fp %>% mutate(left_m := eval(parse(text=v)))
    
    # right
    v <- paste(mi, right, 'n', sep = "_")
    data_fp <- data_fp %>% mutate(right_n := eval(parse(text=v)))
    v <- paste(mi, right, 'sd', sep = "_")
    data_fp <- data_fp %>% mutate(right_sd := eval(parse(text=v)))
    v <- paste(mi, right, 'm', sep = "_")
    data_fp <- data_fp %>% mutate(right_m := eval(parse(text=v)))
    
    data_fp_sub <- data_fp %>%
      select(author, year, cohort_id, cohort_name, name_measurement_instrument, fu_month, left_m, left_sd, left_n, right_m, right_sd, right_n)
    
    # change 1 or 2 into "a" or "b"
    data_fp_sub$cohort_id <-letters[data_fp_sub$cohort_id]
    
    # add column with contrast in first column
    data_fp_sub <- add_column(data_fp_sub, contrast = contrast, .before = 1)
    
    # add column with outcome in first column
    data_fp_sub <- add_column(data_fp_sub, outcome = mi, .before = 1)
    
    # now we can compare the data in e.g. 'check_hrqol_pre-post' with Stefans Excel-sheet
    assign(check_var,data_fp_sub)
    
    ## Eerst had ik de code gemaakt om de verschillende forester plots te maken, later bleek dat je graag de tabel in 'long format' wilde,
    ## daarom zit dat er nu op deze manier in. Achteraf gezien had dit gedaan kunnen worden voordat je de forestplots gaat maken.
    
    # combine all 'check_'-variable into one 'long format' 
    ifelse(exists("data_long"), 
           data_long <- rbind(data_long,data_fp_sub),
           data_long <- data_fp_sub)
    
  }
}


# reversed scoring. Reverse the contrast in case higher scores indicate decreased functioning.  
data_long$rev_scoring <- questionnaires$reverse_scoring[match(as.character(data_long$name_measurement_instrument), as.character(questionnaires$q))]

## reverse scoring procedure ##
data <- data_long
# return: new dataframe with corrected stds and means.
correct_rev_score <- function(data) {
  # Create new copy of data
  rev_corrected_data <- data.frame(data)
  
  # Iterate over each row in data
  for (row in 1:nrow(data)) {
    if (data[row, "rev_scoring"] == 1) {
      # Replace pre by post
      rev_corrected_data[row, "left_m"] <- data[row, "right_m"]
      rev_corrected_data[row, "left_sd"] <- data[row, "right_sd"]
      rev_corrected_data[row, "left_n"] <- data[row, "right_n"]
      
      # Replace post by pre
      rev_corrected_data[row, "right_m"] <- data[row, "left_m"]
      rev_corrected_data[row, "right_sd"] <- data[row, "left_sd"]
      rev_corrected_data[row, "right_n"] <- data[row, "left_n"]
    }
  }
  return(rev_corrected_data)
}
corrected_data <- correct_rev_score(data)

#rename outcomes
corrected_data$outcome <- corrected_data$outcome %>% recode(
  "hrqol" = "health related quality of life",
  "pf" = "physical function",
  "pinter" = "pain interference",
  "dep" =  "depression",
  "anx" = "anxiety",
  "ef" = "general emotional functioning",
  "ang" = "anger",
  "se" = "self-efficacy",
  "srf" = "social functioning",
  "pintens" = "pain intensity"
)

corrected_data <- corrected_data %>%
  mutate(fu_month = if_else(contrast == "pre-post", 0, fu_month))


### static meta analysis ###

static_ma <- corrected_data
static_ma$ri = .59

data_meta <- escalc(measure="SMCR", m1i=right_m, m2i=left_m, sd1i=left_sd, ni=right_n, ri=ri, data=static_ma)
meta_dat <- metafor::summary.escalc(data_meta)
pf_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "physical function")
pf_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "physical function")
pf_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "physical function")
pinter_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "pain interference")
pinter_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "pain interference")
pinter_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "pain interference")
pintens_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "pain intensity")
pintens_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "pain intensity")
pintens_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "pain intensity")
dep_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "depression")
dep_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "depression")
dep_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "depression")
anx_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "anxiety")
anx_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "anxiety")
anx_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "anxiety")
ef_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "general emotional functioning")
ef_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "general emotional functioning")
ef_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "general emotional functioning")
ang_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "anger")
ang_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "anger")
ang_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "anger")
se_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "self-efficacy")
se_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "self-efficacy")
se_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "self-efficacy")
srf_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "social functioning")
srf_meta_pof <- filter(meta_dat, contrast == "post-fu" & outcome == "social functioning")
srf_meta_prf <- filter(meta_dat, contrast == "pre-fu" & outcome == "social functioning")

metavars <- c("author", "year", "cohort_id", "yi", "zi", "ci.lb", "ci.ub")
metavars2 <- c("author", "year", "cohort_id", "outcome", "yi", "zi", "ci.lb", "ci.ub")

#statistical significance of all ES combined.
meta_dat_prpo <- filter(meta_dat, contrast == "pre-post")
summarytools::freq(meta_dat_prpo$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(meta_dat_prpo$ci.lb < 0 & meta_dat_prpo$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(meta_dat_prpo$ci.ub < 0) # - pre follow-up pattern

meta_dat_pof <- filter(meta_dat, contrast == "post-fu")

#pattern total
merge_prpo <- meta_dat_prpo[metavars2]
merge_pof <- meta_dat_pof[metavars2]
meta_merge <- merge(merge_prpo, merge_pof, by = c("author", "year", "cohort_id", "outcome"))

#pattern pre-fu
meta_dat_prf <- filter(meta_dat, contrast == "pre-fu")
summarytools::freq(meta_dat_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(meta_dat_prf$ci.lb < 0 & meta_dat_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(meta_dat_prf$ci.ub < 0) # - pre follow-up pattern

#statistical significance of all ES combined.

total_patterns <- c(
sum(meta_merge$ci.lb.x > 0 & meta_merge$ci.lb.y > 0, na.rm=TRUE), # ++ pattern
sum(meta_merge$ci.lb.x > 0 & meta_merge$ci.lb.y < 0 & meta_merge$ci.ub.y > 0, na.rm=TRUE), # +0 pattern
sum(meta_merge$ci.lb.x > 0 & meta_merge$ci.ub.y < 0, na.rm=TRUE), # +- pattern
sum(meta_merge$ci.lb.x < 0 & meta_merge$ci.ub.x > 0 & meta_merge$ci.lb.y > 0, na.rm=TRUE), # 0+ pattern
sum(meta_merge$ci.lb.x < 0 & meta_merge$ci.ub.x > 0 & meta_merge$ci.lb.y < 0 & meta_merge$ci.ub.y > 0, na.rm=TRUE), # 00 pattern
sum(meta_merge$ci.lb.x < 0 & meta_merge$ci.ub.x > 0 & meta_merge$ci.ub.y < 0, na.rm=TRUE), # 0- pattern
sum(meta_merge$ci.ub.x < 0 & meta_merge$ci.lb.y > 0, na.rm=TRUE), # -+ pattern
sum(meta_merge$ci.ub.x < 0 & meta_merge$ci.lb.y < 0 & meta_merge$ci.ub.y > 0, na.rm=TRUE), # -0 pattern
sum(meta_merge$ci.ub.x < 0 & meta_merge$ci.ub.y < 0, na.rm=TRUE) # -- pattern 
) %>% print()

#create dataframe to obtain absolute and relative numbers of total patterns over time across outcomes.

sum_total_patterns <- sum(total_patterns)
patterns <- c("++", "+0", "+-", "0+", "00", "0-", "-+", "-0", "--")
patterns_table <- bind_cols (patterns, total_patterns)
names(patterns_table)[1] <- "patterns"
names(patterns_table)[2] <- "absolute_count"

patterns_table$percentage <- patterns_table$absolute_count/sum_total_patterns*100
sum(patterns_table$percentage)



#pattern pf
pf_merge_prpo <- pf_meta_prpo[metavars]
pf_merge_pof <- pf_meta_pof[metavars]
pf_merged <- merge(pf_merge_prpo, pf_merge_pof, by = c("author", "year", "cohort_id"))

#pf: count each pattern
sum(pf_merged$ci.lb.x > 0 & pf_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(pf_merged$ci.lb.x > 0 & pf_merged$ci.lb.y < 0 & pf_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(pf_merged$ci.lb.x > 0 & pf_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(pf_merged$ci.lb.x < 0 & pf_merged$ci.ub.x > 0 & pf_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(pf_merged$ci.lb.x < 0 & pf_merged$ci.ub.x > 0 & pf_merged$ci.lb.y < 0 & pf_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(pf_merged$ci.lb.x < 0 & pf_merged$ci.ub.x > 0 & pf_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(pf_merged$ci.ub.x < 0 & pf_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(pf_merged$ci.ub.x < 0 & pf_merged$ci.lb.y < 0 & pf_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(pf_merged$ci.ub.x < 0 & pf_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#pf: pre-fu patterns
summarytools::freq(pf_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(pf_meta_prf$ci.lb < 0 & pf_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(pf_meta_prf$ci.ub < 0) # - pre follow-up pattern


#pattern pinter
pinter_merge_prpo <- pinter_meta_prpo[metavars]
pinter_merge_pof <- pinter_meta_pof[metavars]
pinter_merged <- merge(pinter_merge_prpo, pinter_merge_pof, by = c("author", "year", "cohort_id"))

#pinter: count each pattern
sum(pinter_merged$ci.lb.x > 0 & pinter_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(pinter_merged$ci.lb.x > 0 & pinter_merged$ci.lb.y < 0 & pinter_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(pinter_merged$ci.lb.x > 0 & pinter_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(pinter_merged$ci.lb.x < 0 & pinter_merged$ci.ub.x > 0 & pinter_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(pinter_merged$ci.lb.x < 0 & pinter_merged$ci.ub.x > 0 & pinter_merged$ci.lb.y < 0 & pinter_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(pinter_merged$ci.lb.x < 0 & pinter_merged$ci.ub.x > 0 & pinter_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(pinter_merged$ci.ub.x < 0 & pinter_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(pinter_merged$ci.ub.x < 0 & pinter_merged$ci.lb.y < 0 & pinter_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(pinter_merged$ci.ub.x < 0 & pinter_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#pinter: pre-fu patterns
summarytools::freq(pinter_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(pinter_meta_prf$ci.lb < 0 & pinter_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(pinter_meta_prf$ci.ub < 0) # - pre follow-up pattern


#pattern dep
dep_merge_prpo <- dep_meta_prpo[metavars]
dep_merge_pof <- dep_meta_pof[metavars]
dep_merged <- merge(dep_merge_prpo, dep_merge_pof, by = c("author", "year", "cohort_id"))

#dep: count each pattern
sum(dep_merged$ci.lb.x > 0 & dep_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(dep_merged$ci.lb.x > 0 & dep_merged$ci.lb.y < 0 & dep_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(dep_merged$ci.lb.x > 0 & dep_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(dep_merged$ci.lb.x < 0 & dep_merged$ci.ub.x > 0 & dep_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(dep_merged$ci.lb.x < 0 & dep_merged$ci.ub.x > 0 & dep_merged$ci.lb.y < 0 & dep_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(dep_merged$ci.lb.x < 0 & dep_merged$ci.ub.x > 0 & dep_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(dep_merged$ci.ub.x < 0 & dep_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(dep_merged$ci.ub.x < 0 & dep_merged$ci.lb.y < 0 & dep_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(dep_merged$ci.ub.x < 0 & dep_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#dep: pre-fu patterns
summarytools::freq(dep_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(dep_meta_prf$ci.lb < 0 & dep_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(dep_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern anx
anx_merge_prpo <- anx_meta_prpo[metavars]
anx_merge_pof <- anx_meta_pof[metavars]
anx_merged <- merge(anx_merge_prpo, anx_merge_pof, by = c("author", "year", "cohort_id"))

#anx: count each pattern
sum(anx_merged$ci.lb.x > 0 & anx_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(anx_merged$ci.lb.x > 0 & anx_merged$ci.lb.y < 0 & anx_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(anx_merged$ci.lb.x > 0 & anx_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(anx_merged$ci.lb.x < 0 & anx_merged$ci.ub.x > 0 & anx_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(anx_merged$ci.lb.x < 0 & anx_merged$ci.ub.x > 0 & anx_merged$ci.lb.y < 0 & anx_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(anx_merged$ci.lb.x < 0 & anx_merged$ci.ub.x > 0 & anx_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(anx_merged$ci.ub.x < 0 & anx_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(anx_merged$ci.ub.x < 0 & anx_merged$ci.lb.y < 0 & anx_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(anx_merged$ci.ub.x < 0 & anx_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#anx: pre-fu patterns
summarytools::freq(anx_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(anx_meta_prf$ci.lb < 0 & anx_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(anx_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern ef
ef_merge_prpo <- ef_meta_prpo[metavars]
ef_merge_pof <- ef_meta_pof[metavars]
ef_merged <- merge(ef_merge_prpo, ef_merge_pof, by = c("author", "year", "cohort_id"))

#ef: count each pattern
sum(ef_merged$ci.lb.x > 0 & ef_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(ef_merged$ci.lb.x > 0 & ef_merged$ci.lb.y < 0 & ef_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(ef_merged$ci.lb.x > 0 & ef_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(ef_merged$ci.lb.x < 0 & ef_merged$ci.ub.x > 0 & ef_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(ef_merged$ci.lb.x < 0 & ef_merged$ci.ub.x > 0 & ef_merged$ci.lb.y < 0 & ef_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(ef_merged$ci.lb.x < 0 & ef_merged$ci.ub.x > 0 & ef_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(ef_merged$ci.ub.x < 0 & ef_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(ef_merged$ci.ub.x < 0 & ef_merged$ci.lb.y < 0 & ef_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(ef_merged$ci.ub.x < 0 & ef_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#ef: pre-fu patterns
summarytools::freq(ef_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(ef_meta_prf$ci.lb < 0 & ef_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(ef_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern ang
ang_merge_prpo <- ang_meta_prpo[metavars]
ang_merge_pof <- ang_meta_pof[metavars]
ang_merged <- merge(ang_merge_prpo, ang_merge_pof, by = c("author", "year", "cohort_id"))

#ang: count each pattern
sum(ang_merged$ci.lb.x > 0 & ang_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(ang_merged$ci.lb.x > 0 & ang_merged$ci.lb.y < 0 & ang_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(ang_merged$ci.lb.x > 0 & ang_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(ang_merged$ci.lb.x < 0 & ang_merged$ci.ub.x > 0 & ang_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(ang_merged$ci.lb.x < 0 & ang_merged$ci.ub.x > 0 & ang_merged$ci.lb.y < 0 & ang_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(ang_merged$ci.lb.x < 0 & ang_merged$ci.ub.x > 0 & ang_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(ang_merged$ci.ub.x < 0 & ang_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(ang_merged$ci.ub.x < 0 & ang_merged$ci.lb.y < 0 & ang_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(ang_merged$ci.ub.x < 0 & ang_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#ang: pre-fu patterns
summarytools::freq(ang_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(ang_meta_prf$ci.lb < 0 & ang_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(ang_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern se
se_merge_prpo <- se_meta_prpo[metavars]
se_merge_pof <- se_meta_pof[metavars]
se_merged <- merge(se_merge_prpo, se_merge_pof, by = c("author", "year", "cohort_id"))

#se: count each pattern
sum(se_merged$ci.lb.x > 0 & se_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(se_merged$ci.lb.x > 0 & se_merged$ci.lb.y < 0 & se_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(se_merged$ci.lb.x > 0 & se_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(se_merged$ci.lb.x < 0 & se_merged$ci.ub.x > 0 & se_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(se_merged$ci.lb.x < 0 & se_merged$ci.ub.x > 0 & se_merged$ci.lb.y < 0 & se_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(se_merged$ci.lb.x < 0 & se_merged$ci.ub.x > 0 & se_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(se_merged$ci.ub.x < 0 & se_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(se_merged$ci.ub.x < 0 & se_merged$ci.lb.y < 0 & se_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(se_merged$ci.ub.x < 0 & se_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#se: pre-fu patterns
summarytools::freq(se_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(se_meta_prf$ci.lb < 0 & se_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(se_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern srf
srf_merge_prpo <- srf_meta_prpo[metavars]
srf_merge_pof <- srf_meta_pof[metavars]
srf_merged <- merge(srf_merge_prpo, srf_merge_pof, by = c("author", "year", "cohort_id"))

#srf: count each pattern
sum(srf_merged$ci.lb.x > 0 & srf_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(srf_merged$ci.lb.x > 0 & srf_merged$ci.lb.y < 0 & srf_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(srf_merged$ci.lb.x > 0 & srf_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(srf_merged$ci.lb.x < 0 & srf_merged$ci.ub.x > 0 & srf_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(srf_merged$ci.lb.x < 0 & srf_merged$ci.ub.x > 0 & srf_merged$ci.lb.y < 0 & srf_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(srf_merged$ci.lb.x < 0 & srf_merged$ci.ub.x > 0 & srf_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(srf_merged$ci.ub.x < 0 & srf_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(srf_merged$ci.ub.x < 0 & srf_merged$ci.lb.y < 0 & srf_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(srf_merged$ci.ub.x < 0 & srf_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#srf: pre-fu patterns
summarytools::freq(srf_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(srf_meta_prf$ci.lb < 0 & srf_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(srf_meta_prf$ci.ub < 0) # - pre follow-up pattern

#pattern pintens
pintens_merge_prpo <- pintens_meta_prpo[metavars]
pintens_merge_pof <- pintens_meta_pof[metavars]
pintens_merged <- merge(pintens_merge_prpo, pintens_merge_pof, by = c("author", "year", "cohort_id"))

#pintens: count each pattern
sum(pintens_merged$ci.lb.x > 0 & pintens_merged$ci.lb.y > 0, na.rm=TRUE) # ++ pattern
sum(pintens_merged$ci.lb.x > 0 & pintens_merged$ci.lb.y < 0 & pintens_merged$ci.ub.y > 0, na.rm=TRUE) # +0 pattern
sum(pintens_merged$ci.lb.x > 0 & pintens_merged$ci.ub.y < 0, na.rm=TRUE) # +- pattern
sum(pintens_merged$ci.lb.x < 0 & pintens_merged$ci.ub.x > 0 & pintens_merged$ci.lb.y > 0, na.rm=TRUE) # 0+ pattern
sum(pintens_merged$ci.lb.x < 0 & pintens_merged$ci.ub.x > 0 & pintens_merged$ci.lb.y < 0 & pintens_merged$ci.ub.y > 0, na.rm=TRUE) # 00 pattern
sum(pintens_merged$ci.lb.x < 0 & pintens_merged$ci.ub.x > 0 & pintens_merged$ci.ub.y < 0, na.rm=TRUE) # 0- pattern
sum(pintens_merged$ci.ub.x < 0 & pintens_merged$ci.lb.y > 0, na.rm=TRUE) # -+ pattern
sum(pintens_merged$ci.ub.x < 0 & pintens_merged$ci.lb.y < 0 & pintens_merged$ci.ub.y > 0, na.rm=TRUE) # -0 pattern
sum(pintens_merged$ci.ub.x < 0 & pintens_merged$ci.ub.y < 0, na.rm=TRUE) # -- pattern

#pintens: pre-fu patterns
summarytools::freq(pintens_meta_prf$ci.lb > 0) # + pre-follow-up pattern
summarytools::freq(pintens_meta_prf$ci.lb < 0 & pintens_meta_prf$ci.ub > 0) # 0 pre-follow-up pattern
summarytools::freq(pintens_meta_prf$ci.ub < 0) # - pre follow-up pattern


#PF pre-post#
sum_pf_prpo <- summary(pf_meta_prpo$yi) %>%
  print()

median_pf_prpo <- sum_pf_prpo[3] %>%
  print()


rma(yi, vi, data=pf_meta_prpo)


# PF post-fu #
summary(pf_meta_pof$yi)
rma(yi, vi, data=pf_meta_pof)

# PF pre-fu #
summary(pf_meta_prf$yi)
rma(yi, vi, data=pf_meta_prf)

#Pinter pre-post#
sum_pinter_prpo <- summary(pinter_meta_prpo$yi) %>%
  print()

median_pinter_prpo <- sum_pinter_prpo[3] %>%
  print()

rma(yi, vi, data=pinter_meta_prpo)
unique(pinter_meta_prf$name_measurement_instrument)

#Pinter post-fu#
summary(pinter_meta_pof$yi)
rma(yi, vi, data=pinter_meta_pof)

#Pinter pre-fu#
summary(pinter_meta_prf$yi)
rma(yi, vi, data=pinter_meta_prf)

#Pintens pre-post#
sum_pintens_prpo <- summary(pintens_meta_prpo$yi) %>%
  print()

median_pintens_prpo <- sum_pintens_prpo[3] %>%
  print()

rma(yi, vi, data=pintens_meta_prpo)
unique(pintens_meta_prf$name_measurement_instrument)

#Pintens post-fu#
summary(pintens_meta_pof$yi)
rma(yi, vi, data=pintens_meta_pof)

#Pintens pre-fu#
summary(pintens_meta_prf$yi)
rma(yi, vi, data=pintens_meta_prf)

#dep pre-post#
sum_dep_prpo <- summary(dep_meta_prpo$yi) %>%
  print()

median_dep_prpo <- sum_dep_prpo[3] %>%
  print()

rma(yi, vi, data=dep_meta_prpo)
unique(dep_meta_prf$name_measurement_instrument)

#dep post-fu#
summary(dep_meta_pof$yi)
rma(yi, vi, data=dep_meta_pof)

#dep pre-fu#
summary(dep_meta_prf$yi)
rma(yi, vi, data=dep_meta_prf)

#anx pre-post#
sum_anx_prpo <- summary(anx_meta_prpo$yi) %>%
  print()

median_anx_prpo <- sum_anx_prpo[3] %>%
  print()


rma(yi, vi, data=anx_meta_prpo)
unique(anx_meta_prf$name_measurement_instrument)

#anx post-fu#
summary(anx_meta_pof$yi)
rma(yi, vi, data=anx_meta_pof)

#anx pre-fu#
summary(anx_meta_prf$yi)
rma(yi, vi, data=anx_meta_prf)

#ef pre-post#
sum_ef_prpo <- summary(ef_meta_prpo$yi) %>%
  print()

median_ef_prpo <- sum_ef_prpo[3] %>%
  print()


rma(yi, vi, data=ef_meta_prpo)
unique(ef_meta_prf$name_measurement_instrument)

#ef post-fu#
summary(ef_meta_pof$yi)
rma(yi, vi, data=ef_meta_pof)

#ef pre-fu#
summary(ef_meta_prf$yi)
rma(yi, vi, data=ef_meta_prf)

#ang pre-post#
sum_ang_prpo <- summary(ang_meta_prpo$yi) %>%
  print()

median_ang_prpo <- sum_ang_prpo[3] %>%
  print()

rma(yi, vi, data=ang_meta_prpo)
unique(ang_meta_prf$name_measurement_instrument)

#ang post-fu#
summary(ang_meta_pof$yi)
rma(yi, vi, data=ang_meta_pof)

#ang pre-fu#
summary(ang_meta_prf$yi)
rma(yi, vi, data=ang_meta_prf)

#se pre-post#
sum_se_prpo <- summary(se_meta_prpo$yi) %>%
  print()

median_se_prpo <- sum_se_prpo[3] %>%
  print()

rma(yi, vi, data=se_meta_prpo)
unique(se_meta_prf$name_measurement_instrument)

#se post-fu#
summary(se_meta_pof$yi)
rma(yi, vi, data=se_meta_pof)

#se post-fu#
summary(se_meta_prf$yi)
rma(yi, vi, data=se_meta_prf)

#srf pre-post#
sum_srf_prpo <- summary(srf_meta_prpo$yi) %>%
  print()

median_srf_prpo <- sum_srf_prpo[3] %>%
  print()


rma(yi, vi, data=srf_meta_prpo)
unique(srf_meta_prf$name_measurement_instrument)

#srf post-fu#
summary(srf_meta_pof$yi)
rma(yi, vi, data=srf_meta_pof)

#srf post-fu#
summary(srf_meta_prf$yi)
rma(yi, vi, data=srf_meta_prf)


## Re-express median ES on most common scale

#PF prpo
summarytools::freq(pf_meta_prpo$name_measurement_instrument)
pf_es_scale <- filter(pf_meta_prpo, name_measurement_instrument == "HFAQ") %>%
  select(right_sd, right_n)

pf_es_scale$weighted <- pf_es_scale$right_sd * pf_es_scale$right_n

weighted_sd_pf_prpo <- sum(pf_es_scale$weighted) / sum(pf_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_pf_prpo)

median_pf_prpo * weighted_sd_pf_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#Pinter prpo
summarytools::freq(pinter_meta_prpo$name_measurement_instrument)
pinter_es_scale <- filter(pinter_meta_prpo, name_measurement_instrument == "RMDQ") %>%
  select(right_sd, right_n)

pinter_es_scale$weighted <- pinter_es_scale$right_sd * pinter_es_scale$right_n

weighted_sd_pinter_prpo <- sum(pinter_es_scale$weighted) / sum(pinter_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_pinter_prpo)

median_pinter_prpo * weighted_sd_pinter_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#dep prpo
summarytools::freq(dep_meta_prpo$name_measurement_instrument)
dep_es_scale <- filter(dep_meta_prpo, name_measurement_instrument == "BDI") %>%
  select(right_sd, right_n)

dep_es_scale$weighted <- dep_es_scale$right_sd * dep_es_scale$right_n

weighted_sd_dep_prpo <- sum(dep_es_scale$weighted) / sum(dep_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_dep_prpo)

median_dep_prpo * weighted_sd_dep_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#anx prpo
summarytools::freq(anx_meta_prpo$name_measurement_instrument)
anx_es_scale <- filter(anx_meta_prpo, name_measurement_instrument == "HADS-A") %>%
  select(right_sd, right_n)

anx_es_scale$weighted <- anx_es_scale$right_sd * anx_es_scale$right_n

weighted_sd_anx_prpo <- sum(anx_es_scale$weighted) / sum(anx_es_scale$right_n) # this is the weighted SD of the most commonly used instrument. 
print(weighted_sd_anx_prpo)

median_anx_prpo * weighted_sd_anx_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#ef prpo
summarytools::freq(ef_meta_prpo$name_measurement_instrument)
ef_es_scale <- filter(ef_meta_prpo, name_measurement_instrument == "SF-36: mental health") %>%
  select(right_sd, right_n)

ef_es_scale$weighted <- ef_es_scale$right_sd * ef_es_scale$right_n

weighted_sd_ef_prpo <- sum(ef_es_scale$weighted) / sum(ef_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_ef_prpo)

median_ef_prpo * weighted_sd_ef_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#ang prpo
summarytools::freq(ang_meta_prpo$name_measurement_instrument)
ang_es_scale <- filter(ang_meta_prpo, name_measurement_instrument == "SCL-90: Hostility") %>%
  select(right_sd, right_n)

ang_es_scale$weighted <- ang_es_scale$right_sd * ang_es_scale$right_n

weighted_sd_ang_prpo <- sum(ang_es_scale$weighted) / sum(ang_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_ang_prpo)

median_ang_prpo * weighted_sd_ang_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#SE prpo
summarytools::freq(se_meta_prpo$name_measurement_instrument)
se_es_scale <- filter(se_meta_prpo, name_measurement_instrument == "PSEQ") %>%
  select(right_sd, right_n)

se_es_scale$weighted <- se_es_scale$right_sd * se_es_scale$right_n

weighted_sd_se_prpo <- sum(se_es_scale$weighted) / sum(se_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_se_prpo)

median_se_prpo * weighted_sd_se_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#SRF prpo
summarytools::freq(srf_meta_prpo$name_measurement_instrument)
srf_es_scale <- filter(srf_meta_prpo, name_measurement_instrument == "SF-36: social functioning") %>%
  select(right_sd, right_n)

srf_es_scale$weighted <- srf_es_scale$right_sd * srf_es_scale$right_n

weighted_sd_srf_prpo <- sum(srf_es_scale$weighted) / sum(srf_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_srf_prpo)

median_srf_prpo * weighted_sd_srf_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

#Pintens prpo
summarytools::freq(pintens_meta_prpo$name_measurement_instrument)
pintens_es_scale <- filter(pintens_meta_prpo, name_measurement_instrument == "VAS") %>%
  select(right_sd, right_n)

pintens_es_scale$weighted <- pintens_es_scale$right_sd * pintens_es_scale$right_n

weighted_sd_pintens_prpo <- sum(pintens_es_scale$weighted) / sum(pintens_es_scale$right_n) # this is the weighted SD of the most commonly used instrument.
print(weighted_sd_pintens_prpo)

median_pintens_prpo * weighted_sd_pintens_prpo # this is the conversion of the median effect size to the most frequently used instrument on that particular outcome.

## create static forest plot for testing lay-out
data_testfp <- escalc(measure="SMCR", m1i=right_m, m2i=left_m, sd1i=left_sd, ni=right_n, ri=ri, data=static_ma) %>%
  metafor::summary.escalc() %>%
  filter(contrast == "pre-post" & outcome == "physical function")


tabletext <- cbind(c("author", data_testfp$author),
                   c("year", data_testfp$year))

forestplot(tabletext, data_testfp$yi, data_testfp$ci.lb, data_testfp$ci.ub,
           xlab = "<---favors pre---     ---favors post--->",
           txt_gp=fpTxtGp(label=gpar(cex=1),
                          ticks=gpar(cex=.6),
                          xlab=gpar(cex = 1),
                          title=gpar(cex = 1.1)),
           col=fpColors(box="black", lines="black", zero = "gray50"),
           zero=0, cex=0.5, lineheight = unit(1, "cm"), boxsize=0.3,
           lwd.ci=2, ci.vertices=TRUE, ci.vertices.height = .1, grid=TRUE,
           align = "l",
           graph.pos = "right",
           clip = c(-4, 4),
           alim = c(-4,4))




## create shinyapp ##

#step1: create tibble for corrected data
data_fp <- as_tibble(corrected_data)

#step 2: create Shinyapp
ui <- fluidPage(
  
  # App title ----
  headerPanel("Forest plot systematic review"),
  
  # Sidebar layout with input and output definitions ----
  sidebarLayout(
    
    # Sidebar panel for inputs ----
    sidebarPanel(
      
      # Input: Slider for the number of bins ----
      sliderInput(inputId = "r_value",
                  label = "R Correction Value:",
                  min = 0,
                  max = 1,
                  value = 0,
                  step = 0.1),
      
      selectInput(inputId = "outcome",
                  label = "select ouctome:",
                  choices = c("health related quality of life", "physical function", "pain interference", "depression", "anxiety",   
                              "self-efficacy", "social functioning", "pain intensity", "anger", "general emotional functioning"),
                  selected = "pain interference"),
      
      selectInput(inputId = "contrast",
                  label = "select contrast:",
                  choices = c("pre-post", "post-fu", "pre-fu"),
                  selected = "pre-post")
    ),
    
    # Main panel for displaying outputs ----
    mainPanel(
      
      # Output: Histogram ----
      plotOutput("forestplot", height = "1300px"), width = 12
      
    )
  )
)
# Define server logic required to draw a histogram ----
server <- function(input, output, session) {
  
  
  output$forestplot <- renderPlot({
    
    data_fp$ri <- input$r_value
    data_fp_meta <- escalc(measure="SMCR", m1i=right_m, m2i=left_m, sd1i=left_sd, ni=right_n, ri=ri, data=data_fp)
    fp_meta <- metafor::summary.escalc(data_fp_meta)
    fp_meta2 <- filter(fp_meta, contrast == input$contrast & outcome == input$outcome)
    fp_meta2$tabletext <- cbind(fp_meta2$author, fp_meta2$year, fp_meta2$right_n, fp_meta2$name_measurement_instrument, 
                                fp_meta2$fu_month)
    
    forestplot(fp_meta2$tabletext, fp_meta2$yi, fp_meta2$ci.lb, fp_meta2$ci.ub,
               xlab = "<---favors---     ---favors post--->",
               txt_gp=fpTxtGp(label=gpar(cex=1),
                              ticks=gpar(cex=.6),
                              xlab=gpar(cex = 1),
                              title=gpar(cex = 1.1)),
               col=fpColors(box="black", lines="black", zero = "gray50"),
               zero=0, cex=0.5, lineheight = unit(1, "cm"), boxsize=0.3,
               lwd.ci=2, ci.vertices=TRUE, ci.vertices.height = .1, grid=TRUE,
               align = "l",
               graph.pos = "right",
               clip = c(-4, 4),
               alim = c(-4,4)
    )
  })
  
}

shinyApp(ui=ui, server=server)


#test sorting dataset
pf_meta_prpo <- filter(meta_dat, contrast == "pre-post" & outcome == "physical function")
pf_meta_prpo <- pf_meta_prpo[order(pf_meta_prpo$right_n) ,]

                 